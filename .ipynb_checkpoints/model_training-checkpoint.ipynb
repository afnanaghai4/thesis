{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "369b307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data related imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder,MinMaxScaler\n",
    "\n",
    "from huggingface_hub import login,HfApi, upload_file\n",
    "\n",
    "\n",
    "# classification model imports\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# deep learning model imports\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f849c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:/masters material/thesis/datasets/Edge-IIoTset dataset/Selected dataset for ML and DL/ML-EdgeIIoT-dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0604a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef464e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba04233",
   "metadata": {},
   "source": [
    "# decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Step 1: Drop object columns\n",
    "X = df.drop(columns=['Attack_label'])  # Drop target and any duplicates\n",
    "X = X.select_dtypes(include=['int64', 'float64', 'bool'])  # Keep numeric features only\n",
    "\n",
    "# Step 2: Set target\n",
    "y = df['Attack_label']\n",
    "\n",
    "# Train-val-test split: 70/20/10\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, stratify=y_temp, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68fa3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train class distribution:\\n\", y_train.value_counts())\n",
    "print(\"Validation class distribution:\\n\", y_val.value_counts())\n",
    "print(\"Test class distribution:\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a394c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"X columns:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267241ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,       # Disable the label encoder warning\n",
    "    objective='binary:logistic',   # Important: binary classification objective\n",
    "    eval_metric='logloss'          # Evaluation metric\n",
    ")\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True  # Optional: shows training log\n",
    ")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "model.save_model(\"xgb_model.json\")\n",
    "\n",
    "# upload_file(\n",
    "#     path_or_fileobj=\"xgb_model.json\",  # or \"xgb_model.pkl\"\n",
    "#     path_in_repo=\"xgb_model.json\",     # File name in the repo\n",
    "#     repo_id=\"ScHemer34/DT_XGBoost\",\n",
    "#     repo_type=\"model\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=['normal', 'attack']))\n",
    "\n",
    "# Print duration\n",
    "training_duration = end_time - start_time\n",
    "print(f\"\\n‚úÖ Model trained in {training_duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8533c351",
   "metadata": {},
   "source": [
    "# Dataset for Deep Learning Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b16554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afnan\\AppData\\Local\\Temp\\ipykernel_11820\\2324740219.py:1: DtypeWarning: Columns (2,3,6,11,13,14,15,16,17,31,32,34,39,45,51,54,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_fnn = pd.read_csv(\"E:/masters material/thesis/datasets/Edge-IIoTset dataset/Selected dataset for ML and DL/DNN-EdgeIIoT-dataset.csv\")  # adjust path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2219201, 63)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2219201 entries, 0 to 2219200\n",
      "Data columns (total 63 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   frame.time                 object \n",
      " 1   ip.src_host                object \n",
      " 2   ip.dst_host                object \n",
      " 3   arp.dst.proto_ipv4         object \n",
      " 4   arp.opcode                 float64\n",
      " 5   arp.hw.size                float64\n",
      " 6   arp.src.proto_ipv4         object \n",
      " 7   icmp.checksum              float64\n",
      " 8   icmp.seq_le                float64\n",
      " 9   icmp.transmit_timestamp    float64\n",
      " 10  icmp.unused                float64\n",
      " 11  http.file_data             object \n",
      " 12  http.content_length        float64\n",
      " 13  http.request.uri.query     object \n",
      " 14  http.request.method        object \n",
      " 15  http.referer               object \n",
      " 16  http.request.full_uri      object \n",
      " 17  http.request.version       object \n",
      " 18  http.response              float64\n",
      " 19  http.tls_port              float64\n",
      " 20  tcp.ack                    float64\n",
      " 21  tcp.ack_raw                float64\n",
      " 22  tcp.checksum               float64\n",
      " 23  tcp.connection.fin         float64\n",
      " 24  tcp.connection.rst         float64\n",
      " 25  tcp.connection.syn         float64\n",
      " 26  tcp.connection.synack      float64\n",
      " 27  tcp.dstport                float64\n",
      " 28  tcp.flags                  float64\n",
      " 29  tcp.flags.ack              float64\n",
      " 30  tcp.len                    float64\n",
      " 31  tcp.options                object \n",
      " 32  tcp.payload                object \n",
      " 33  tcp.seq                    float64\n",
      " 34  tcp.srcport                object \n",
      " 35  udp.port                   float64\n",
      " 36  udp.stream                 float64\n",
      " 37  udp.time_delta             float64\n",
      " 38  dns.qry.name               float64\n",
      " 39  dns.qry.name.len           object \n",
      " 40  dns.qry.qu                 float64\n",
      " 41  dns.qry.type               float64\n",
      " 42  dns.retransmission         float64\n",
      " 43  dns.retransmit_request     float64\n",
      " 44  dns.retransmit_request_in  float64\n",
      " 45  mqtt.conack.flags          object \n",
      " 46  mqtt.conflag.cleansess     float64\n",
      " 47  mqtt.conflags              float64\n",
      " 48  mqtt.hdrflags              float64\n",
      " 49  mqtt.len                   float64\n",
      " 50  mqtt.msg_decoded_as        float64\n",
      " 51  mqtt.msg                   object \n",
      " 52  mqtt.msgtype               float64\n",
      " 53  mqtt.proto_len             float64\n",
      " 54  mqtt.protoname             object \n",
      " 55  mqtt.topic                 object \n",
      " 56  mqtt.topic_len             float64\n",
      " 57  mqtt.ver                   float64\n",
      " 58  mbtcp.len                  float64\n",
      " 59  mbtcp.trans_id             float64\n",
      " 60  mbtcp.unit_id              float64\n",
      " 61  Attack_label               int64  \n",
      " 62  Attack_type                object \n",
      "dtypes: float64(42), int64(1), object(20)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df_fnn = pd.read_csv(\"E:/masters material/thesis/datasets/Edge-IIoTset dataset/Selected dataset for ML and DL/DNN-EdgeIIoT-dataset.csv\")  # adjust path\n",
    "print(df_fnn.shape)\n",
    "df_fnn.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c493fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lstm = pd.read_csv(\"E:/masters material/thesis/datasets/Edge-IIoTset dataset/Selected dataset for ML and DL/DNN-EdgeIIoT-dataset.csv\")  # adjust path\n",
    "print(df_lstm.shape)\n",
    "df_lstm.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9d6ea",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c6ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LinearNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.output = nn.Linear(8, 1)  # Output = 1 for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.output(x)  # No sigmoid here if using BCEWithLogitsLoss\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d07d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df_fnn.dropna(inplace=True)\n",
    "\n",
    "#encoding important columns\n",
    "# Initialize encoder\n",
    "method_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform\n",
    "df_fnn['http.request.method_encoded'] = method_encoder.fit_transform(df_fnn['http.request.method'].astype(str))\n",
    "df_fnn['http.request.version_encoded'] = np.where(df_fnn['http.request.version'].astype(str).str.strip() == '0', 0, 1)\n",
    "df_fnn['mqtt_topic'] = method_encoder.fit_transform(df_fnn['mqtt.topic'].astype(str))\n",
    "df_fnn['mqtt_protoname'] = method_encoder.fit_transform(df_fnn['mqtt.protoname'].astype(str))\n",
    "df_fnn['Attack_type'] = np.where(df_fnn['Attack_type'].astype(str).str.strip() == 'normal', 0, 1)\n",
    "\n",
    "\n",
    "# Step 2: Set target\n",
    "y_fnn = df_fnn['Attack_label']\n",
    "\n",
    "# Now drop object and unnecessary columns\n",
    "X_fnn = df_fnn.drop(columns=[\n",
    "    'Attack_label', 'http.request.full_uri', 'http.referer', 'http.file_data', \n",
    "    'tcp.payload', 'frame.time', 'mqtt.msg', 'tcp.options', 'dns.qry.name', \n",
    "    'http.request.method', 'http.request.version', 'mqtt.topic', 'mqtt.protoname','ip.src_host',\n",
    "    'ip.dst_host','arp.dst.proto_ipv4','arp.src.proto_ipv4','http.request.uri.query','tcp.srcport',\n",
    "    'dns.qry.name.len','mqtt.conack.flags'\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91257a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# First split: Train 70%, Temp 30%\n",
    "X_train_fnn, X_temp_fnn, y_train_fnn, y_temp_fnn = train_test_split(\n",
    "    X_fnn, y_fnn, test_size=0.3, stratify=y_fnn, random_state=42\n",
    ")\n",
    "\n",
    "# Second split: Validation 20% (2/3 of 30%), Test 10% (1/3 of 30%)\n",
    "X_val_fnn, X_test_fnn, y_val_fnn, y_test_fnn = train_test_split(\n",
    "    X_temp_fnn, y_temp_fnn, test_size=1/3, stratify=y_temp_fnn, random_state=42\n",
    ")\n",
    "\n",
    "# Reset indices to avoid any overlap when converting to NumPy later\n",
    "X_train_fnn = X_train_fnn.reset_index(drop=True)\n",
    "X_val_fnn = X_val_fnn.reset_index(drop=True)\n",
    "X_test_fnn = X_test_fnn.reset_index(drop=True)\n",
    "\n",
    "y_train_fnn = y_train_fnn.reset_index(drop=True)\n",
    "y_val_fnn = y_val_fnn.reset_index(drop=True)\n",
    "y_test_fnn = y_test_fnn.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccb33578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Val Overlap: 69374\n"
     ]
    }
   ],
   "source": [
    "overlap = set(map(tuple, X_train_fnn.values)) & set(map(tuple, X_val_fnn.values))\n",
    "print(f\"Train/Val Overlap: {len(overlap)}\")  # Should be 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7eaba97d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train class distribution:\n",
      " Attack_label\n",
      "0    1130950\n",
      "1     422490\n",
      "Name: count, dtype: int64\n",
      "Validation class distribution:\n",
      " Attack_label\n",
      "0    323128\n",
      "1    120712\n",
      "Name: count, dtype: int64\n",
      "Test class distribution:\n",
      " Attack_label\n",
      "0    161565\n",
      "1     60356\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train class distribution:\\n\", y_train_fnn.value_counts())\n",
    "print(\"Validation class distribution:\\n\", y_val_fnn.value_counts())\n",
    "print(\"Test class distribution:\\n\", y_test_fnn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9a5b96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_fnn.columns:\n",
    "    if X_fnn[col].apply(type).nunique() > 1:\n",
    "        print(f\"{col}: {X_fnn[col].apply(type).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4614bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fnn.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1820ff5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n"
     ]
    }
   ],
   "source": [
    "#normalize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_fnn = scaler.fit_transform(X_train_fnn)\n",
    "# X_val_fnn = scaler.transform(X_val_fnn)\n",
    "# X_test_fnn = scaler.transform(X_test_fnn)\n",
    "\n",
    "print(X_fnn.dtypes[X_fnn.dtypes == 'object'])\n",
    "\n",
    "# convert dataframe to pytorch tensors\n",
    "X_train_tensor_fnn = torch.tensor(X_train_fnn.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor_fnn = torch.tensor(y_train_fnn.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "X_val_tensor_fnn = torch.tensor(X_val_fnn.to_numpy(), dtype=torch.float32)\n",
    "y_val_tensor_fnn = torch.tensor(y_val_fnn.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3986e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 14127033.0000, Val Loss: 14088618.0000\n",
      "Epoch [2/30], Loss: 14086947.0000, Val Loss: 14048589.0000\n",
      "Epoch [3/30], Loss: 14046937.0000, Val Loss: 14008634.0000\n",
      "Epoch [4/30], Loss: 14007001.0000, Val Loss: 13968753.0000\n",
      "Epoch [5/30], Loss: 13967140.0000, Val Loss: 13928954.0000\n",
      "Epoch [6/30], Loss: 13927359.0000, Val Loss: 13889229.0000\n",
      "Epoch [7/30], Loss: 13887656.0000, Val Loss: 13849585.0000\n",
      "Epoch [8/30], Loss: 13848032.0000, Val Loss: 13810023.0000\n",
      "Epoch [9/30], Loss: 13808487.0000, Val Loss: 13770543.0000\n",
      "Epoch [10/30], Loss: 13769025.0000, Val Loss: 13731145.0000\n",
      "Epoch [11/30], Loss: 13729648.0000, Val Loss: 13691829.0000\n",
      "Epoch [12/30], Loss: 13690354.0000, Val Loss: 13652601.0000\n",
      "Epoch [13/30], Loss: 13651143.0000, Val Loss: 13613455.0000\n",
      "Epoch [14/30], Loss: 13612017.0000, Val Loss: 13574398.0000\n",
      "Epoch [15/30], Loss: 13572977.0000, Val Loss: 13535428.0000\n",
      "Epoch [16/30], Loss: 13534027.0000, Val Loss: 13496546.0000\n",
      "Epoch [17/30], Loss: 13495163.0000, Val Loss: 13457751.0000\n",
      "Epoch [18/30], Loss: 13456388.0000, Val Loss: 13419045.0000\n",
      "Epoch [19/30], Loss: 13417703.0000, Val Loss: 13380432.0000\n",
      "Epoch [20/30], Loss: 13379107.0000, Val Loss: 13341908.0000\n",
      "Epoch [21/30], Loss: 13340601.0000, Val Loss: 13303477.0000\n",
      "Epoch [22/30], Loss: 13302189.0000, Val Loss: 13265136.0000\n",
      "Epoch [23/30], Loss: 13263868.0000, Val Loss: 13226889.0000\n",
      "Epoch [24/30], Loss: 13225640.0000, Val Loss: 13188734.0000\n",
      "Epoch [25/30], Loss: 13187504.0000, Val Loss: 13150674.0000\n",
      "Epoch [26/30], Loss: 13149461.0000, Val Loss: 13112705.0000\n",
      "Epoch [27/30], Loss: 13111512.0000, Val Loss: 13074830.0000\n",
      "Epoch [28/30], Loss: 13073655.0000, Val Loss: 13037049.0000\n",
      "Epoch [29/30], Loss: 13035893.0000, Val Loss: 12999363.0000\n",
      "Epoch [30/30], Loss: 12998225.0000, Val Loss: 12961772.0000\n"
     ]
    }
   ],
   "source": [
    "# Start timer\n",
    "start_time_fnn = time.time()\n",
    "\n",
    "model_fnn = LinearNN(input_size=X_train_fnn.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_fnn.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model_fnn.train()\n",
    "    \n",
    "    outputs = model_fnn(X_train_tensor_fnn).squeeze()\n",
    "    loss = criterion(outputs, y_train_tensor_fnn.float())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate validation loss\n",
    "    model_fnn.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients during validation\n",
    "        val_outputs = model_fnn(X_val_tensor_fnn).squeeze()\n",
    "        val_loss = criterion(val_outputs, y_val_tensor_fnn.float())\n",
    "\n",
    "    # Print epoch information\n",
    "    model_fnn.train()  # Set model back to training mode\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# End timer\n",
    "end_time_fnn = time.time()\n",
    "\n",
    "torch.save(model_fnn.state_dict(), \"linear_nn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3f23467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test Accuracy: 0.7280\n",
      "‚è±Ô∏è Model trained in 12.76 seconds\n"
     ]
    }
   ],
   "source": [
    "model_fnn.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test_fnn.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test_fnn.values, dtype=torch.float32)\n",
    "\n",
    "    outputs = model_fnn(X_test_tensor).squeeze()\n",
    "    probs = torch.sigmoid(outputs)\n",
    "    preds = (probs > 0.5).float()\n",
    "\n",
    "    correct = (preds == y_test_tensor).sum().item()\n",
    "    accuracy = correct / y_test_tensor.shape[0]\n",
    "\n",
    "print(f\"\\nüß™ Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print duration\n",
    "training_duration_fnn = end_time_fnn - start_time_fnn\n",
    "print(f\"‚è±Ô∏è Model trained in {training_duration_fnn:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10160086",
   "metadata": {},
   "source": [
    "# Long Short Term Memory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1c180df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import BinaryCrossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d2d30704",
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 1\n",
    "\n",
    "num_features = X_train_fnn.shape[1]\n",
    "\n",
    "# --- Step 1: Convert DataFrames to NumPy Arrays ---\n",
    "X_train_np = X_train_fnn.to_numpy()\n",
    "y_train_np = y_train_fnn.to_numpy().reshape(-1, 1)\n",
    "\n",
    "X_val_np = X_val_fnn.to_numpy()\n",
    "y_val_np = y_val_fnn.to_numpy().reshape(-1, 1)\n",
    "\n",
    "# --- Step 2: Scale Features ---\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_np)\n",
    "X_val_scaled = scaler.transform(X_val_np)  # use transform only on val\n",
    "\n",
    "X_train_lstm = X_train_scaled.reshape(-1, timesteps, num_features)\n",
    "X_val_lstm = X_val_scaled.reshape(-1, timesteps, num_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "192477c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overlapping samples: 69374\n"
     ]
    }
   ],
   "source": [
    "intersection = set(map(tuple, X_train_np)) & set(map(tuple, X_val_np))\n",
    "print(f\"Overlapping samples: {len(intersection)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "16e5f9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afnan\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m24273/24273\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0299 - val_accuracy: 1.0000 - val_loss: 1.8871e-11\n",
      "Epoch 2/2\n",
      "\u001b[1m24273/24273\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2ms/step - accuracy: 1.0000 - loss: 2.8114e-08 - val_accuracy: 1.0000 - val_loss: 1.0822e-13\n",
      "training duration is: 98.37376022338867\n"
     ]
    }
   ],
   "source": [
    "# ---------- 2. Define LSTM model ----------\n",
    "model = Sequential()\n",
    "model.add(LSTM(32, return_sequences=False, input_shape=(timesteps, num_features)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "\n",
    "# Step 5: Train\n",
    "start_time_lstm = time.time()\n",
    "history = model.fit(\n",
    "    X_train_lstm, \n",
    "    y_train_np,                # use y_full if labels are binary\n",
    "    validation_data=(X_val_lstm, y_val_np), #validation checking dataset\n",
    "    epochs=2,\n",
    "    batch_size=64,\n",
    "    callbacks=[early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "end_time_lstm = time.time()\n",
    "training_duration_lstm = end_time_lstm - start_time_lstm\n",
    "print(f\"training duration is: {training_duration_lstm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c012191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ---------- 4. Check loss over time ----------\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'])\n",
    "plt.title('Loss over Epochs (Overfitting Test)')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1dd8d21f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test_fnn shape: (221921, 46)\n",
      "timesteps: 1\n",
      "num_features: 46\n"
     ]
    }
   ],
   "source": [
    "print(\"x_test_fnn shape:\", X_test_fnn.shape)\n",
    "print(\"timesteps:\", timesteps)\n",
    "print(\"num_features:\", num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1ed449a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_array shape: (221921, 46)\n",
      "X_test_lstm shape: (221921, 1, 46)\n"
     ]
    }
   ],
   "source": [
    "X_test_array = X_test_fnn.to_numpy()  # Convert to numpy array\n",
    "y_test_np = y_test_fnn.to_numpy().reshape(-1, 1)\n",
    "\n",
    "# Check shape of X_test_array\n",
    "print(\"X_test_array shape:\", X_test_array.shape)\n",
    "\n",
    "# Reshape to (samples, timesteps, num_features)\n",
    "X_test_lstm = X_test_array.reshape((X_test_array.shape[0], timesteps, num_features))\n",
    "print(\"X_test_lstm shape:\", X_test_lstm.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b22d7d39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6936/6936\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.8258 - loss: 1.9018\n",
      "Test Loss: 1.8798\n",
      "Test Accuracy: 0.8270\n",
      "\u001b[1m6936/6936\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.96      0.89    161565\n",
      "           1       0.81      0.47      0.60     60356\n",
      "\n",
      "    accuracy                           0.83    221921\n",
      "   macro avg       0.82      0.72      0.74    221921\n",
      "weighted avg       0.83      0.83      0.81    221921\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "test_loss, test_accuracy = model.evaluate(X_test_lstm, y_test_np, verbose=1)\n",
    "print(f\"Test Loss: {test_loss:.4f}\")\n",
    "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Predict\n",
    "y_pred_prob = model.predict(X_test_lstm)\n",
    "y_pred = (y_pred_prob > 0.5).astype(int)\n",
    "\n",
    "# Print classification report\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test_np, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8a6dd682",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test_lstm shape: (221921, 1, 46)\n",
      "y_test_np shape: (221921,)\n",
      "X_test_lstm dtype: float64\n",
      "y_test_np dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"X_test_lstm shape:\", X_test_lstm.shape)\n",
    "print(\"y_test_np shape:\", y_test_np.shape)\n",
    "print(\"X_test_lstm dtype:\", X_test_lstm.dtype)\n",
    "print(\"y_test_np dtype:\", y_test_np.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e1f0268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as lstm\n",
    "\n",
    "class LSTMModel(lstm.Module):\n",
    "    def __init__(self, input_size, hidden_size=32):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm1 = lstm.LSTM(input_size=input_size, hidden_size=hidden_size, batch_first=True)\n",
    "#         self.lstm2 = nn.LSTM(input_size=hidden_size, hidden_size=hidden_size, batch_first=True)\n",
    "        self.fc = lstm.Linear(hidden_size, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm1(x)\n",
    "#         out, _ = self.lstm2(out)  # note: this should take 'out' from lstm1\n",
    "        out = out[:, -1, :]\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8e52b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Step 1: Scale the features\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled_lstm = scaler.fit_transform(X_train_fnn)\n",
    "X_val_scaled_lstm = scaler.transform(X_val_fnn)\n",
    "X_test_scaled_lstm = scaler.transform(X_test_fnn)\n",
    "\n",
    "\n",
    "# Step 2: Convert features to tensors (and unsqueeze for LSTM shape: [batch, seq_len, input_size])\n",
    "X_train_tensor_lstm = torch.tensor(X_train_scaled_lstm, dtype=torch.float32).unsqueeze(1)\n",
    "X_val_tensor_lstm = torch.tensor(X_val_scaled_lstm, dtype=torch.float32).unsqueeze(1)\n",
    "X_test_tensor_lstm = torch.tensor(X_test_scaled_lstm, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Step 2: Convert features to tensors (and unsqueeze for LSTM shape: [batch, seq_len, input_size])\n",
    "# X_train_tensor_lstm = torch.tensor(X_train_fnn.values, dtype=torch.float32).unsqueeze(1)\n",
    "# X_val_tensor_lstm = torch.tensor(X_val_fnn.values, dtype=torch.float32).unsqueeze(1)\n",
    "# X_test_tensor_lstm = torch.tensor(X_test_fnn.values, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Step 3: Convert targets to tensors (and unsqueeze for [batch_size, 1] if needed)\n",
    "y_train_tensor_lstm = torch.tensor(y_train_fnn.to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "y_val_tensor_lstm = torch.tensor(y_val_fnn.to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "y_test_tensor_lstm = torch.tensor(y_test_fnn.to_numpy(), dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "# Step 4: Set the device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "\n",
    "# 3. Wrap tensors into a Dataset\n",
    "train_dataset = TensorDataset(X_train_tensor_lstm, y_train_tensor_lstm)\n",
    "val_dataset = TensorDataset(X_val_tensor_lstm, y_val_tensor_lstm)\n",
    "test_dataset = TensorDataset(X_test_tensor_lstm, y_test_tensor_lstm)\n",
    "\n",
    "# 4. Use DataLoader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)  # You can tune the batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "640d83ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.27197059988975525\n"
     ]
    }
   ],
   "source": [
    "print(y_train_tensor_lstm.mean().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93339dde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 0, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 1, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 2, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 3, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 4, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 5, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 6, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 7, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 8, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 9, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 10, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 11, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 12, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 13, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 14, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 15, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 16, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 17, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 18, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 19, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 20, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 21, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 22, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 23, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 24, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 25, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 26, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 27, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 28, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 29, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 30, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 31, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 32, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 33, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 34, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 35, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 36, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 37, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 38, Loss: 0.2094\n",
      "out range: 0.04480889439582825 0.13782501220703125\n",
      "Epoch 39, Loss: 0.2094\n"
     ]
    }
   ],
   "source": [
    "# Use a small subset\n",
    "input_size = 46\n",
    "model_lstm = LSTMModel(input_size=input_size).to(device)\n",
    "\n",
    "criterion = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "X_small = X_small[:, :, -5:]  # Last 5 columns where values are non-zero\n",
    "X_small = X_train_tensor_lstm[:32].to(device)\n",
    "y_small = y_train_tensor_lstm[:32].to(device)\n",
    "\n",
    "\n",
    "model_lstm = LSTMModel(input_size=input_size).to(device)\n",
    "\n",
    "for i in range(40):\n",
    "    model_lstm.train()\n",
    "    optimizer.zero_grad()\n",
    "    out = model_lstm(X_small)\n",
    "    loss = criterion(out, y_small)\n",
    "    print(\"out range:\", out.min().item(), out.max().item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {i}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d1e667a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out.shape torch.Size([32, 1])\n",
      "y_small shape: torch.Size([32, 1])\n"
     ]
    }
   ],
   "source": [
    "print(\"out.shape\", out.shape)\n",
    "print(\"y_small shape:\", y_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac6a41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.  0.  0.  ... 1.  0.5 0.5]\n",
      " [0.  0.  0.  ... 1.  0.  0. ]\n",
      " [0.  0.  0.  ... 1.  0.  0. ]\n",
      " ...\n",
      " [0.  0.  0.  ... 1.  0.  0. ]\n",
      " [0.  0.  0.  ... 1.  0.  0. ]\n",
      " [0.  0.  0.  ... 1.  0.5 0.5]]\n"
     ]
    }
   ],
   "source": [
    "print(X_small.squeeze().cpu().numpy())  # shape (32, 46)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "54c4b9e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "print(y_small.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f925720d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_small shape: torch.Size([32, 1, 46])\n"
     ]
    }
   ],
   "source": [
    "print(\"X_small shape:\", X_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "592787ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.27292519 0.16396384 0.10222466 0.08529597 0.0666497 ]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "X_np = X_train_tensor_lstm.squeeze(1).cpu().numpy()\n",
    "pca = PCA(n_components=5)\n",
    "X_reduced = pca.fit_transform(X_np)\n",
    "\n",
    "print(pca.explained_variance_ratio_)  # see how much signal is in first few features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb5938a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "37e897db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train label distribution: (tensor([0., 1.]), tensor([1130950,  422490]))\n",
      "Val label distribution: (tensor([0., 1.]), tensor([323128, 120712]))\n"
     ]
    }
   ],
   "source": [
    "print(\"Train label distribution:\", torch.unique(y_train_tensor_lstm, return_counts=True))\n",
    "print(\"Val label distribution:\", torch.unique(y_val_tensor_lstm, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf6cacce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.27197059988975525 Std: 0.44497495889663696\n",
      "Val: 0.2719718813896179 Std: 0.44497597217559814\n"
     ]
    }
   ],
   "source": [
    "print(\"Train:\", y_train_tensor_lstm.mean().item(), \"Std:\", y_train_tensor_lstm.std().item())\n",
    "print(\"Val:\", y_val_tensor_lstm.mean().item(), \"Std:\", y_val_tensor_lstm.std().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a7d69d71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input example: tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.4391, 0.0000, 0.0000, 1.0000, 0.0000, 0.0287, 0.0800,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1250, 1.0000, 0.0000,\n",
      "         0.0000]])\n",
      "Target example: tensor([0.])\n"
     ]
    }
   ],
   "source": [
    "print(\"Input example:\", X_train_tensor_lstm[4])\n",
    "print(\"Target example:\", y_train_tensor_lstm[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b1bed",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "torch.backends.mkldnn.enabled = False\n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "input_size = X_train_tensor_lstm.shape[2]\n",
    "model_lstm = LSTMModel(input_size=input_size).to(device)\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 15\n",
    "start_time_lstm = time.time()\n",
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model_lstm.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_lstm(X_batch)\n",
    "#         print(outputs[:5].detach().cpu().numpy())\n",
    "#         print(y_batch[:5].cpu().numpy())\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        for name, param in model_lstm.named_parameters():\n",
    "            if param.grad is not None:\n",
    "                print(f\"{name}: {param.grad.abs().mean().item():.6f}\")\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item() * X_batch.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model_lstm.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for X_val_batch, y_val_batch in val_loader:\n",
    "            X_val_batch, y_val_batch = X_val_batch.to(device), y_val_batch.to(device)\n",
    "            val_outputs = model_lstm(X_val_batch)\n",
    "            loss = criterion(val_outputs, y_val_batch)\n",
    "            val_loss += loss.item() * X_val_batch.size(0)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "end_time_lstm = time.time()\n",
    "training_duration_lstm = end_time_lstm - start_time_lstm\n",
    "\n",
    "# Save the model\n",
    "torch.save(model_lstm.state_dict(), \"lstm_model.pth\")\n",
    "print(f\"\\nTraining time: {training_duration_lstm:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403a5a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_lstm.eval()\n",
    "with torch.no_grad():\n",
    "    example_output = model_lstm(X_val_tensor_lstm[:5])\n",
    "    print(\"Sample outputs:\", example_output.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef19a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train and Val X equal?\", torch.equal(X_train_tensor_lstm, X_val_tensor_lstm))\n",
    "print(\"Train and Val y equal?\", torch.equal(y_train_tensor_lstm, y_val_tensor_lstm))\n",
    "print(\"Train size:\", len(train_dataset))\n",
    "print(\"Val size:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1b84f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "model_lstm.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X_batch, y_batch in test_loader:\n",
    "        X_batch, y_batch = X_batch.to(device), y_batch.to(device)\n",
    "        outputs = model_lstm(X_batch)\n",
    "        predicted = torch.sigmoid(outputs)\n",
    "        predicted_classes = (predicted >= 0.5).float()\n",
    "        \n",
    "        all_preds.append(predicted_classes)\n",
    "        all_labels.append(y_batch)\n",
    "\n",
    "# Concatenate all predictions and labels\n",
    "all_preds = torch.cat(all_preds)\n",
    "all_labels = torch.cat(all_labels)\n",
    "\n",
    "# Accuracy\n",
    "accuracy = (all_preds == all_labels).float().mean()\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training duration: {training_duration_lstm:.2f} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641dc578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7fc2c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
