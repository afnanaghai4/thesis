{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e812862b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler,LabelEncoder\n",
    "\n",
    "from huggingface_hub import login,HfApi, upload_file\n",
    "\n",
    "\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f849c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('E:/masters material/thesis/datasets/Edge-IIoTset dataset/Selected dataset for ML and DL/ML-EdgeIIoT-dataset.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0604a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Attack_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365bd79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ad1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44edad89",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69b27c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef464e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c40c536",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba04233",
   "metadata": {},
   "source": [
    "# decision tree classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61d4eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Step 1: Drop object columns\n",
    "X = df.drop(columns=['Attack_label'])  # Drop target and any duplicates\n",
    "X = X.select_dtypes(include=['int64', 'float64', 'bool'])  # Keep numeric features only\n",
    "\n",
    "# Step 2: Set target\n",
    "y = df['Attack_label']\n",
    "\n",
    "# Train-val-test split: 70/20/10\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, stratify=y_temp, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68fa3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train class distribution:\\n\", y_train.value_counts())\n",
    "print(\"Validation class distribution:\\n\", y_val.value_counts())\n",
    "print(\"Test class distribution:\\n\", y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a394c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"X shape:\", X.shape)\n",
    "print(\"X columns:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267241ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=6,\n",
    "    subsample=0.8,\n",
    "    colsample_bytree=0.8,\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,       # Disable the label encoder warning\n",
    "    objective='binary:logistic',   # Important: binary classification objective\n",
    "    eval_metric='logloss'          # Evaluation metric\n",
    ")\n",
    "\n",
    "# Start timer\n",
    "start_time = time.time()\n",
    "\n",
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=True  # Optional: shows training log\n",
    ")\n",
    "\n",
    "# End timer\n",
    "end_time = time.time()\n",
    "\n",
    "model.save_model(\"xgb_model.json\")\n",
    "\n",
    "# upload_file(\n",
    "#     path_or_fileobj=\"xgb_model.json\",  # or \"xgb_model.pkl\"\n",
    "#     path_in_repo=\"xgb_model.json\",     # File name in the repo\n",
    "#     repo_id=\"ScHemer34/DT_XGBoost\",\n",
    "#     repo_type=\"model\"\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b2fe43",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Test Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred, target_names=['normal', 'attack']))\n",
    "\n",
    "# Print duration\n",
    "training_duration = end_time - start_time\n",
    "print(f\"\\n‚úÖ Model trained in {training_duration:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd9d6ea",
   "metadata": {},
   "source": [
    "# Feed Forward Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b16554e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\afnan\\AppData\\Local\\Temp\\ipykernel_8920\\2324740219.py:1: DtypeWarning: Columns (2,3,6,11,13,14,15,16,17,31,32,34,39,45,51,54,55) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_fnn = pd.read_csv(\"E:/masters material/thesis/datasets/Edge-IIoTset dataset/Selected dataset for ML and DL/DNN-EdgeIIoT-dataset.csv\")  # adjust path\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2219201, 63)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2219201 entries, 0 to 2219200\n",
      "Data columns (total 63 columns):\n",
      " #   Column                     Dtype  \n",
      "---  ------                     -----  \n",
      " 0   frame.time                 object \n",
      " 1   ip.src_host                object \n",
      " 2   ip.dst_host                object \n",
      " 3   arp.dst.proto_ipv4         object \n",
      " 4   arp.opcode                 float64\n",
      " 5   arp.hw.size                float64\n",
      " 6   arp.src.proto_ipv4         object \n",
      " 7   icmp.checksum              float64\n",
      " 8   icmp.seq_le                float64\n",
      " 9   icmp.transmit_timestamp    float64\n",
      " 10  icmp.unused                float64\n",
      " 11  http.file_data             object \n",
      " 12  http.content_length        float64\n",
      " 13  http.request.uri.query     object \n",
      " 14  http.request.method        object \n",
      " 15  http.referer               object \n",
      " 16  http.request.full_uri      object \n",
      " 17  http.request.version       object \n",
      " 18  http.response              float64\n",
      " 19  http.tls_port              float64\n",
      " 20  tcp.ack                    float64\n",
      " 21  tcp.ack_raw                float64\n",
      " 22  tcp.checksum               float64\n",
      " 23  tcp.connection.fin         float64\n",
      " 24  tcp.connection.rst         float64\n",
      " 25  tcp.connection.syn         float64\n",
      " 26  tcp.connection.synack      float64\n",
      " 27  tcp.dstport                float64\n",
      " 28  tcp.flags                  float64\n",
      " 29  tcp.flags.ack              float64\n",
      " 30  tcp.len                    float64\n",
      " 31  tcp.options                object \n",
      " 32  tcp.payload                object \n",
      " 33  tcp.seq                    float64\n",
      " 34  tcp.srcport                object \n",
      " 35  udp.port                   float64\n",
      " 36  udp.stream                 float64\n",
      " 37  udp.time_delta             float64\n",
      " 38  dns.qry.name               float64\n",
      " 39  dns.qry.name.len           object \n",
      " 40  dns.qry.qu                 float64\n",
      " 41  dns.qry.type               float64\n",
      " 42  dns.retransmission         float64\n",
      " 43  dns.retransmit_request     float64\n",
      " 44  dns.retransmit_request_in  float64\n",
      " 45  mqtt.conack.flags          object \n",
      " 46  mqtt.conflag.cleansess     float64\n",
      " 47  mqtt.conflags              float64\n",
      " 48  mqtt.hdrflags              float64\n",
      " 49  mqtt.len                   float64\n",
      " 50  mqtt.msg_decoded_as        float64\n",
      " 51  mqtt.msg                   object \n",
      " 52  mqtt.msgtype               float64\n",
      " 53  mqtt.proto_len             float64\n",
      " 54  mqtt.protoname             object \n",
      " 55  mqtt.topic                 object \n",
      " 56  mqtt.topic_len             float64\n",
      " 57  mqtt.ver                   float64\n",
      " 58  mbtcp.len                  float64\n",
      " 59  mbtcp.trans_id             float64\n",
      " 60  mbtcp.unit_id              float64\n",
      " 61  Attack_label               int64  \n",
      " 62  Attack_type                object \n",
      "dtypes: float64(42), int64(1), object(20)\n",
      "memory usage: 1.0+ GB\n"
     ]
    }
   ],
   "source": [
    "df_fnn = pd.read_csv(\"E:/masters material/thesis/datasets/Edge-IIoTset dataset/Selected dataset for ML and DL/DNN-EdgeIIoT-dataset.csv\")  # adjust path\n",
    "print(df_fnn.shape)\n",
    "df_fnn.info()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85c6ecf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class LinearNN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(LinearNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.relu1 = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.relu2 = nn.LeakyReLU(negative_slope=0.01)\n",
    "        self.output = nn.Linear(8, 1)  # Output = 1 for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.output(x)  # No sigmoid here if using BCEWithLogitsLoss\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d07d8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with missing values\n",
    "df_fnn.dropna(inplace=True)\n",
    "\n",
    "#encoding important columns\n",
    "# Initialize encoder\n",
    "method_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform\n",
    "df_fnn['http.request.method_encoded'] = method_encoder.fit_transform(df_fnn['http.request.method'].astype(str))\n",
    "df_fnn['http.request.version_encoded'] = np.where(df_fnn['http.request.version'].astype(str).str.strip() == '0', 0, 1)\n",
    "df_fnn['mqtt_topic'] = method_encoder.fit_transform(df_fnn['mqtt.topic'].astype(str))\n",
    "df_fnn['mqtt_protoname'] = method_encoder.fit_transform(df_fnn['mqtt.protoname'].astype(str))\n",
    "df_fnn['Attack_type'] = np.where(df_fnn['Attack_type'].astype(str).str.strip() == 'normal', 0, 1)\n",
    "\n",
    "\n",
    "# Step 2: Set target\n",
    "y_fnn = df_fnn['Attack_label']\n",
    "\n",
    "# Now drop object and unnecessary columns\n",
    "X_fnn = df_fnn.drop(columns=[\n",
    "    'Attack_label', 'http.request.full_uri', 'http.referer', 'http.file_data', \n",
    "    'tcp.payload', 'frame.time', 'mqtt.msg', 'tcp.options', 'dns.qry.name', \n",
    "    'http.request.method', 'http.request.version', 'mqtt.topic', 'mqtt.protoname','ip.src_host',\n",
    "    'ip.dst_host','arp.dst.proto_ipv4','arp.src.proto_ipv4','http.request.uri.query','tcp.srcport',\n",
    "    'dns.qry.name.len','mqtt.conack.flags'\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Train-val-test split: 70/20/10\n",
    "X_train_fnn, X_temp_fnn, y_train_fnn, y_temp_fnn = train_test_split(X_fnn, y_fnn, test_size=0.3, stratify=y_fnn, random_state=42)\n",
    "X_val_fnn, X_test_fnn, y_val_fnn, y_test_fnn = train_test_split(X_temp_fnn, y_temp_fnn, test_size=1/3, stratify=y_temp_fnn, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a072695b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Train class distribution:\\n\", y_train_fnn.value_counts())\n",
    "print(\"Validation class distribution:\\n\", y_val_fnn.value_counts())\n",
    "print(\"Test class distribution:\\n\", y_test_fnn.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330f5406",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in X_fnn.columns:\n",
    "    if X_fnn[col].apply(type).nunique() > 1:\n",
    "        print(f\"{col}: {X_fnn[col].apply(type).value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7797b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fnn.info()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d39dd8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Series([], dtype: object)\n"
     ]
    }
   ],
   "source": [
    "#normalize the data\n",
    "# scaler = StandardScaler()\n",
    "# X_train_fnn = scaler.fit_transform(X_train_fnn)\n",
    "# X_val_fnn = scaler.transform(X_val_fnn)\n",
    "# X_test_fnn = scaler.transform(X_test_fnn)\n",
    "\n",
    "print(X_fnn.dtypes[X_fnn.dtypes == 'object'])\n",
    "\n",
    "# convert dataframe to pytorch tensors\n",
    "X_train_tensor_fnn = torch.tensor(X_train_fnn.to_numpy(), dtype=torch.float32)\n",
    "y_train_tensor_fnn = torch.tensor(y_train_fnn.to_numpy(), dtype=torch.float32)\n",
    "\n",
    "X_val_tensor_fnn = torch.tensor(X_val_fnn.to_numpy(), dtype=torch.float32)\n",
    "y_val_tensor_fnn = torch.tensor(y_val_fnn.to_numpy(), dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3986e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/30], Loss: 804007.5625, Val Loss: 759611.0000\n",
      "Epoch [2/30], Loss: 760345.2500, Val Loss: 716059.6250\n",
      "Epoch [3/30], Loss: 716740.2500, Val Loss: 672566.6250\n",
      "Epoch [4/30], Loss: 673193.7500, Val Loss: 629131.5000\n",
      "Epoch [5/30], Loss: 629705.3125, Val Loss: 585756.5625\n",
      "Epoch [6/30], Loss: 586277.1250, Val Loss: 542441.3125\n",
      "Epoch [7/30], Loss: 542908.5625, Val Loss: 499186.9375\n",
      "Epoch [8/30], Loss: 499600.9062, Val Loss: 455993.2812\n",
      "Epoch [9/30], Loss: 456354.2188, Val Loss: 412861.1875\n",
      "Epoch [10/30], Loss: 413169.0312, Val Loss: 369790.0938\n",
      "Epoch [11/30], Loss: 370044.8125, Val Loss: 326780.6562\n",
      "Epoch [12/30], Loss: 326982.3125, Val Loss: 283833.3125\n",
      "Epoch [13/30], Loss: 283982.0312, Val Loss: 240945.5625\n",
      "Epoch [14/30], Loss: 241041.3281, Val Loss: 198118.7031\n",
      "Epoch [15/30], Loss: 198161.5469, Val Loss: 155351.0000\n",
      "Epoch [16/30], Loss: 155340.9844, Val Loss: 112641.6484\n",
      "Epoch [17/30], Loss: 112578.8359, Val Loss: 70058.0391\n",
      "Epoch [18/30], Loss: 69943.9531, Val Loss: 27966.6367\n",
      "Epoch [19/30], Loss: 27810.2012, Val Loss: 26157.3789\n",
      "Epoch [20/30], Loss: 26001.8613, Val Loss: 34067.5156\n",
      "Epoch [21/30], Loss: 33912.9844, Val Loss: 40985.2617\n",
      "Epoch [22/30], Loss: 40831.8984, Val Loss: 47004.5352\n",
      "Epoch [23/30], Loss: 46852.5000, Val Loss: 52207.7109\n",
      "Epoch [24/30], Loss: 52057.1328, Val Loss: 56668.9414\n",
      "Epoch [25/30], Loss: 56519.9570, Val Loss: 60454.5625\n",
      "Epoch [26/30], Loss: 60307.2812, Val Loss: 63624.1484\n",
      "Epoch [27/30], Loss: 63478.6602, Val Loss: 66231.1953\n",
      "Epoch [28/30], Loss: 66087.6016, Val Loss: 68324.5156\n",
      "Epoch [29/30], Loss: 68182.8750, Val Loss: 69947.8672\n",
      "Epoch [30/30], Loss: 69808.2656, Val Loss: 71141.0781\n"
     ]
    }
   ],
   "source": [
    "# Start timer\n",
    "start_time_fnn = time.time()\n",
    "\n",
    "model_fnn = LinearNN(input_size=X_train_fnn.shape[1])\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model_fnn.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 30\n",
    "for epoch in range(num_epochs):\n",
    "    model_fnn.train()\n",
    "    \n",
    "    outputs = model_fnn(X_train_tensor_fnn).squeeze()\n",
    "    loss = criterion(outputs, y_train_tensor_fnn.float())\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Calculate validation loss\n",
    "    model_fnn.eval()  # Set model to evaluation mode\n",
    "    with torch.no_grad():  # No need to track gradients during validation\n",
    "        val_outputs = model_fnn(X_val_tensor_fnn).squeeze()\n",
    "        val_loss = criterion(val_outputs, y_val_tensor_fnn.float())\n",
    "\n",
    "    # Print epoch information\n",
    "    model_fnn.train()  # Set model back to training mode\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}\")\n",
    "\n",
    "\n",
    "# End timer\n",
    "end_time_fnn = time.time()\n",
    "\n",
    "torch.save(model_fnn.state_dict(), \"linear_nn_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f23467d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üß™ Test Accuracy: 0.7619\n",
      "‚è±Ô∏è Model trained in 12.33 seconds\n"
     ]
    }
   ],
   "source": [
    "model_fnn.eval()\n",
    "with torch.no_grad():\n",
    "    X_test_tensor = torch.tensor(X_test_fnn.values, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test_fnn.values, dtype=torch.float32)\n",
    "\n",
    "    outputs = model_fnn(X_test_tensor).squeeze()\n",
    "    probs = torch.sigmoid(outputs)\n",
    "    preds = (probs > 0.5).float()\n",
    "\n",
    "    correct = (preds == y_test_tensor).sum().item()\n",
    "    accuracy = correct / y_test_tensor.shape[0]\n",
    "\n",
    "print(f\"\\nüß™ Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Print duration\n",
    "training_duration_fnn = end_time_fnn - start_time_fnn\n",
    "print(f\"‚è±Ô∏è Model trained in {training_duration_fnn:.2f} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fd94f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1f0268",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "759b1bed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
